<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI Notes</title>
    <link>https://notes.muthu.co/</link>
    <description>Recent content on AI Notes</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 16 Jul 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://notes.muthu.co/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Measuring Massive Multitask Language Understanding: Why MMLU Matters and What It Really Tests</title>
      <link>https://notes.muthu.co/2025/07/measuring-massive-multitask-language-understanding-why-mmlu-matters-and-what-it-really-tests/</link>
      <pubDate>Wed, 16 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://notes.muthu.co/2025/07/measuring-massive-multitask-language-understanding-why-mmlu-matters-and-what-it-really-tests/</guid>
      <description>&lt;p&gt;I remember the first time I heard about MMLU. I was reading about GPT-3&amp;rsquo;s capabilities, and there it was - this benchmark that claimed to test AI across 57 different subjects. From elementary math to professional law, from world history to computer science. It sounded almost too ambitious to be real.&lt;/p&gt;&#xA;&lt;p&gt;But here&amp;rsquo;s the thing about MMLU (Measuring Massive Multitask Language Understanding) - it&amp;rsquo;s become one of the most important ways we measure how smart our AI systems really are. And after diving deep into it, I think it&amp;rsquo;s worth understanding what makes it special.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding Mixture of Experts (MoE) from First Principles</title>
      <link>https://notes.muthu.co/2025/07/understanding-mixture-of-experts-moe-from-first-principles/</link>
      <pubDate>Sun, 13 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://notes.muthu.co/2025/07/understanding-mixture-of-experts-moe-from-first-principles/</guid>
      <description>&lt;p&gt;One of the most exciting architectural innovations in recent years is the &lt;strong&gt;Mixture of Experts (MoE)&lt;/strong&gt;. It&amp;rsquo;s a key reason why models like Mistral&amp;rsquo;s Mixtral and (reportedly) OpenAI&amp;rsquo;s GPT-4 are so powerful.&lt;/p&gt;&#xA;&lt;p&gt;To really understand MoE, let’s go back to first principles.&#xA;Here’s a rewritten version of your article with a &lt;strong&gt;Flesch Reading Ease score above 70&lt;/strong&gt;. The language is simpler and more direct, while keeping the core ideas intact.&lt;/p&gt;</description>
    </item>
    <item>
      <title>My Thoughts on Andrew Ng&#39;s &#34;Building Faster and Smarter with AI&#34;</title>
      <link>https://notes.muthu.co/2025/07/my-thoughts-on-andrew-ngs-building-faster-and-smarter-with-ai/</link>
      <pubDate>Fri, 11 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://notes.muthu.co/2025/07/my-thoughts-on-andrew-ngs-building-faster-and-smarter-with-ai/</guid>
      <description>&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;&#xA;      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/RNJCfif1dPY?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;&#xA;    &lt;/div&gt;&#xA;&#xA;&lt;p&gt;I watched Andrew Ng&amp;rsquo;s latest talk on AI startup strategy, and while I disagree with some of the hype, there are genuinely useful insights buried in the promotional language. Here&amp;rsquo;s what caught my attention. Ng isn&amp;rsquo;t chasing the latest transformer variant or arguing about AGI timelines. He&amp;rsquo;s focused on something much more important: how AI actually helps people build useful things faster.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Agent Communication Protocols MCP, ACP, A2A, and ANP</title>
      <link>https://notes.muthu.co/2025/07/ai-agent-communication-protocols-mcp-acp-a2a-and-anp/</link>
      <pubDate>Wed, 09 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://notes.muthu.co/2025/07/ai-agent-communication-protocols-mcp-acp-a2a-and-anp/</guid>
      <description>&lt;p&gt;As artificial intelligence becomes more sophisticated, we are moving from single AI models to complex systems of multiple AI agents working together. These multi-agent systems (MAS) have the potential to solve incredibly complex problems, but they face a fundamental challenge: how do the agents talk to each other?&lt;/p&gt;&#xA;&lt;p&gt;Just like humans need language to cooperate, AI agents need communication protocols. These protocols are the rules of the road for AI interaction, defining how agents can exchange information, request actions, and work together on tasks. This post explores four of the most promising agent communication protocols (ACPs) and what they mean for the future of AI.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Small Language Models are the Future of Agentic AI</title>
      <link>https://notes.muthu.co/2025/07/small-language-models-are-the-future-of-agentic-ai/</link>
      <pubDate>Tue, 08 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://notes.muthu.co/2025/07/small-language-models-are-the-future-of-agentic-ai/</guid>
      <description>&lt;p&gt;I recently came across a paper titled &lt;em&gt;&amp;ldquo;Small Language Models are the Future of Agentic AI,&amp;rdquo;&lt;/em&gt; and it got me thinking. The message is simple but powerful: bigger isn&amp;rsquo;t always better.&lt;/p&gt;&#xA;&lt;p&gt;In the current AI landscape, we often assume that more power equals more performance. But this paper challenges that assumption. Instead, it offers a smarter and more strategic view of how AI can scale without scaling costs.&lt;/p&gt;&#xA;&lt;p&gt;Let’s break it down.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Meet AlphaEvolve: The AI That Discovers New Algorithms</title>
      <link>https://notes.muthu.co/2025/07/meet-alphaevolve-the-ai-that-discovers-new-algorithms/</link>
      <pubDate>Mon, 07 Jul 2025 10:00:00 +0530</pubDate>
      <guid>https://notes.muthu.co/2025/07/meet-alphaevolve-the-ai-that-discovers-new-algorithms/</guid>
      <description>&lt;p&gt;Imagine a coding partner that doesn’t just write software, but &lt;strong&gt;iteratively evolves it&lt;/strong&gt;, learns from its mistakes, and even &lt;strong&gt;discovers brand-new algorithms&lt;/strong&gt; some better than anything a human has ever designed.&lt;/p&gt;&#xA;&lt;p&gt;Sounds like science fiction, right? Well, it’s exactly what &lt;a href=&#34;https://arxiv.org/abs/2506.13131&#34;&gt;&lt;strong&gt;AlphaEvolve&lt;/strong&gt;&lt;/a&gt;, a new breakthrough from DeepMind, is all about.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;so-what-exactly-is-alphaevolve&#34;&gt;So, What Exactly is AlphaEvolve?&lt;/h2&gt;&#xA;&lt;p&gt;At its heart, &lt;strong&gt;AlphaEvolve&lt;/strong&gt; is an AI agent that’s been built to do one thing: &lt;em&gt;discover new and better code through evolution&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Learning CrewAI: A Step-by-Step Guide in 10 Concepts</title>
      <link>https://notes.muthu.co/2025/07/learning-crewai-a-step-by-step-guide-in-10-concepts/</link>
      <pubDate>Sun, 06 Jul 2025 14:00:00 +0530</pubDate>
      <guid>https://notes.muthu.co/2025/07/learning-crewai-a-step-by-step-guide-in-10-concepts/</guid>
      <description>&lt;p&gt;CrewAI is a cutting-edge framework for orchestrating autonomous AI agents. It allows you to build sophisticated multi-agent systems that can collaborate to solve complex problems. This guide breaks down CrewAI into 10 fundamental concepts, taking you from first principles to building a complete, end-to-end agentic workflow.&lt;/p&gt;&#xA;&lt;h3 id=&#34;concept-1-the-agent&#34;&gt;&lt;strong&gt;Concept 1: The Agent&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Fundamental Idea:&lt;/strong&gt; An Agent is an autonomous entity designed to perform specific roles, achieve goals, and execute tasks. Think of it as a specialized member of your AI team. Each agent has a unique role, a goal that defines its purpose, and a backstory that provides context and personality. This allows agents to behave in a more specialized and predictable way.&lt;/p&gt;</description>
    </item>
    <item>
      <title>About</title>
      <link>https://notes.muthu.co/about/</link>
      <pubDate>Sun, 06 Jul 2025 10:00:00 +0530</pubDate>
      <guid>https://notes.muthu.co/about/</guid>
      <description>&lt;h1 id=&#34;about-me&#34;&gt;About Me&lt;/h1&gt;&#xA;&lt;p&gt;Hello! I&amp;rsquo;m &lt;strong&gt;Muthu Krishnan&lt;/strong&gt;, an Engineering Manager at Sanas with over 15 years of experience building scalable SaaS applications. I&amp;rsquo;m passionate about the intersection of AI, software engineering, and innovative technology.&lt;/p&gt;&#xA;&lt;h2 id=&#34;professional-background&#34;&gt;Professional Background&lt;/h2&gt;&#xA;&lt;p&gt;Currently working as a Software Engineer at Sanas, I specialize in developing robust, scalable software solutions with a focus on AI and machine learning technologies. My expertise spans across multiple programming languages and technologies, with particular strength in Java, C++, and AI systems.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Keeping Your AI Code-Gen Up-to-Date: An Introduction to Context Engineering</title>
      <link>https://notes.muthu.co/2025/07/keeping-your-ai-code-gen-up-to-date-an-introduction-to-context-engineering/</link>
      <pubDate>Wed, 02 Jul 2025 12:00:00 +0530</pubDate>
      <guid>https://notes.muthu.co/2025/07/keeping-your-ai-code-gen-up-to-date-an-introduction-to-context-engineering/</guid>
      <description>&lt;p&gt;One of the most common frustrations with AI coding assistants is their tendency to generate code that is outdated or relies on deprecated libraries. This happens because the Large Language Models (LLMs) that power these assistants are trained on vast but static datasets. By the time a model is released, the libraries and frameworks it was trained on may have already been updated.&lt;/p&gt;&#xA;&lt;p&gt;This is where &lt;strong&gt;context engineering&lt;/strong&gt; comes in. Instead of relying on the LLM&amp;rsquo;s outdated knowledge, we can provide it with up-to-date information directly in the prompt. This ensures that the generated code is current, correct, and uses the latest best practices.&lt;/p&gt;</description>
    </item>
    <item>
      <title>A Developer&#39;s Guide to Effective AI Coding Agents</title>
      <link>https://notes.muthu.co/2025/07/a-developers-guide-to-effective-ai-coding-agents/</link>
      <pubDate>Tue, 01 Jul 2025 11:00:00 +0530</pubDate>
      <guid>https://notes.muthu.co/2025/07/a-developers-guide-to-effective-ai-coding-agents/</guid>
      <description>&lt;p&gt;AI-powered coding assistants are rapidly evolving from simple auto-completion tools into sophisticated, &lt;strong&gt;collaborative agents&lt;/strong&gt;. While it&amp;rsquo;s tempting to offload entire tasks to these systems, the most effective approach is a &lt;em&gt;guided&lt;/em&gt; one, where the developer remains the architect and the AI acts as a highly efficient executor.&lt;/p&gt;&#xA;&lt;p&gt;This guide outlines a structured workflow for leveraging AI coding agents, ensuring you maintain control, improve code quality, and boost your productivity.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-developer-as-architect&#34;&gt;&lt;strong&gt;The Developer as Architect&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;The fundamental principle of effective AI collaboration is that &lt;strong&gt;the developer must lead the process&lt;/strong&gt;. Over-delegating to an AI without a clear plan can lead to a loss of context, architectural drift, and code that is difficult to maintain.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deep Research Applications of Modern LLMs Generated through Deep Research</title>
      <link>https://notes.muthu.co/2025/03/deep-research-applications-of-modern-llms-generated-through-deep-research/</link>
      <pubDate>Sat, 22 Mar 2025 10:00:00 +0530</pubDate>
      <guid>https://notes.muthu.co/2025/03/deep-research-applications-of-modern-llms-generated-through-deep-research/</guid>
      <description>&lt;p&gt;Artificial Intelligence is moving beyond conversational chatbots to become &lt;em&gt;autonomous research agents&lt;/em&gt;. Unlike conventional LLM assistants that answer questions based on pre-trained knowledge, these new systems—collectively called &lt;strong&gt;Deep Research AI&lt;/strong&gt;—can:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Plan and execute multi-step investigations&lt;/li&gt;&#xA;&lt;li&gt;Formulate sub-questions and hypotheses&lt;/li&gt;&#xA;&lt;li&gt;Browse the web and databases iteratively&lt;/li&gt;&#xA;&lt;li&gt;Evaluate sources and compile structured reports with citations&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This process, while slower, achieves comprehensive, verifiable insights comparable to a PhD-level literature review.&lt;/p&gt;&#xA;&lt;h2 id=&#34;how-deep-research-works&#34;&gt;&lt;strong&gt;How Deep Research Works&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Core Stages:&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
