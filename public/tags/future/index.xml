<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Future on AI Notes</title>
    <link>https://notes.muthu.co/tags/future/</link>
    <description>Recent content in Future on AI Notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Jul 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://notes.muthu.co/tags/future/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Small Language Models are the Future of Agentic AI</title>
      <link>https://notes.muthu.co/2025/07/small-language-models-are-the-future-of-agentic-ai/</link>
      <pubDate>Tue, 08 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://notes.muthu.co/2025/07/small-language-models-are-the-future-of-agentic-ai/</guid>
      <description>I recently came across a paper titled &amp;ldquo;Small Language Models are the Future of Agentic AI,&amp;rdquo; and it got me thinking. The message is simple but powerful: bigger isn&amp;rsquo;t always better.&#xA;In the current AI landscape, we often assume that more power equals more performance. But this paper challenges that assumption. Instead, it offers a smarter and more strategic view of how AI can scale without scaling costs.&#xA;Letâ€™s break it down.</description>
    </item>
  </channel>
</rss>
