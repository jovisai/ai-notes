<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Systems-Architecture on Engineering Notes</title>
    <link>http://localhost:1313/tags/systems-architecture/</link>
    <description>Recent content in Systems-Architecture on Engineering Notes</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Nov 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/systems-architecture/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>The Architecture is the Prompt - Guiding AI with Hexagonal Design</title>
      <link>http://localhost:1313/2025/11/the-architecture-is-the-prompt-guiding-ai-with-hexagonal-design/</link>
      <pubDate>Wed, 12 Nov 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2025/11/the-architecture-is-the-prompt-guiding-ai-with-hexagonal-design/</guid>
      <description>&lt;p&gt;As developers, we&amp;rsquo;ve all felt the frustration. You have a well-structured repository with clear patterns, but the new AI coding assistant you&amp;rsquo;re working with seems determined to ignore them. Despite providing documentation, examples, and explicit instructions in your prompts, the AI generates code that tangles concerns, bypasses your service layers, and writes directly to the database from a controller.&lt;/p&gt;&#xA;&lt;p&gt;The immediate reaction is to blame the tool and focus on &amp;ldquo;better prompt engineering.&amp;rdquo; We try longer, more detailed prompts, hoping that with enough context, the AI will finally understand. But this is often a losing battle. The problem isn&amp;rsquo;t just the prompt; it&amp;rsquo;s that we&amp;rsquo;re asking the AI to understand the invisible, implicit rules of a complex system.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
